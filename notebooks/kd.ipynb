{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325ce8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_traces.data_processing.data_processing import (\n",
    "    get_no_shuffle_train_loader,\n",
    "    get_num_classes,\n",
    "    get_trainset,\n",
    "    get_testset,\n",
    "    prepare_transform,\n",
    "    prepare_loaders,)\n",
    "from loss_traces.models.model import load_model\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ae8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcdb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_DIR = \"trained_models\"\n",
    "config = {\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    \"arch\": \"wrn28-2\",\n",
    "    \"batchsize\": 16,\n",
    "    \"num_workers\": 4,\n",
    "    \"augment\": True,\n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "\n",
    "\n",
    "def _initialize_model_and_data(config):\n",
    "    attack_loaders = [\n",
    "        get_no_shuffle_train_loader(\n",
    "            config[\"dataset\"],\n",
    "            config[\"arch\"],\n",
    "            config[\"batchsize\"],\n",
    "            config[\"num_workers\"],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if config[\"augment\"]:\n",
    "        attack_loaders.append(\n",
    "            get_no_shuffle_train_loader(\n",
    "                config[\"dataset\"],\n",
    "                config[\"arch\"],\n",
    "                config[\"batchsize\"],\n",
    "                config[\"num_workers\"],\n",
    "                mirror_all=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model = load_model(config[\"arch\"], get_num_classes(config[\"dataset\"])).to(\n",
    "        config[\"device\"]\n",
    "    )\n",
    "\n",
    "    return model, attack_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795243d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load student and teacher models\n",
    "teacher_exp_id = \"wrn28-2_CIFAR_5_l0\"\n",
    "student_exp_id = \"wrn28-2_CIFAR_5_l3\"\n",
    "\n",
    "teacher, dataloader = _initialize_model_and_data(config)\n",
    "teacher_saves = torch.load(f\"{MODEL_DIR}/models/{teacher_exp_id}/target\", weights_only=False)\n",
    "teacher.load_state_dict(teacher_saves[\"model_state_dict\"])\n",
    "\n",
    "student, _ = _initialize_model_and_data(config)\n",
    "saves = torch.load(f\"{MODEL_DIR}/models/{student_exp_id}/target\", weights_only=False)\n",
    "# student.load_state_dict(saves[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff735e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_mask_logits(logits, masking_strength=1.0, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Apply confidence masking: preserve rank order but randomize confidence values\n",
    "    \n",
    "    Args:\n",
    "        logits: original model logits [batch_size, num_classes]\n",
    "        masking_strength: how much to randomize (0=no masking, 1=full random)\n",
    "        temperature: temperature for softmax conversion\n",
    "    \n",
    "    Returns:\n",
    "        masked_logits: logits with preserved order but masked confidence\n",
    "    \"\"\"\n",
    "    batch_size, num_classes = logits.shape\n",
    "    device = logits.device\n",
    "    \n",
    "    # Get the ranking (order) of original predictions\n",
    "    _, original_rankings = torch.sort(logits, dim=1, descending=True)\n",
    "    \n",
    "    # Generate random confidence values for each sample\n",
    "    if masking_strength > 0:\n",
    "        # Random values between 0 and masking_strength\n",
    "        random_confidences = torch.rand(batch_size, num_classes, device=device) * masking_strength\n",
    "        \n",
    "        # Create new logits that preserve ranking but use random confidences\n",
    "        masked_logits = torch.zeros_like(logits)\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            # Sort the random confidences in descending order\n",
    "            sorted_random, _ = torch.sort(random_confidences[batch_idx], descending=True)\n",
    "            \n",
    "            # Assign these sorted random values according to original ranking\n",
    "            for rank_idx, class_idx in enumerate(original_rankings[batch_idx]):\n",
    "                masked_logits[batch_idx, class_idx] = sorted_random[rank_idx]\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        masked_logits = masked_logits / temperature\n",
    "        \n",
    "    else:\n",
    "        # No masking, return original logits\n",
    "        masked_logits = logits / temperature\n",
    "    \n",
    "    return masked_logits\n",
    "\n",
    "\n",
    "class ConfidenceMaskedKnowledgeDistillation(nn.Module):\n",
    "    def __init__(self, temperature=3.0, alpha=0.7, masking_strength=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.masking_strength = masking_strength\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, student_logits, teacher_logits, targets):\n",
    "        ce_loss = self.ce_loss(student_logits, targets)\n",
    "        \n",
    "        # Apply confidence masking to teacher logits\n",
    "        masked_teacher_logits = confidence_mask_logits(\n",
    "            teacher_logits, \n",
    "            masking_strength=self.masking_strength,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        \n",
    "        # Knowledge distillation \n",
    "        soft_targets = F.softmax(masked_teacher_logits / self.temperature, dim=1)\n",
    "        soft_predictions = F.log_softmax(student_logits / self.temperature, dim=1)\n",
    "        \n",
    "        kd_loss = F.kl_div(soft_predictions, soft_targets, reduction='batchmean') * (self.temperature ** 2)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = (1 - self.alpha) * ce_loss + self.alpha * kd_loss\n",
    "        \n",
    "        return total_loss, ce_loss, kd_loss\n",
    "\n",
    "def train_with_confidence_masked_kd(teacher_model, student_model, train_loader, \n",
    "                                  optimizer, device, temperature=3.0, \n",
    "                                  alpha=0.7, masking_strength=0.5):\n",
    "    \"\"\"\n",
    "    Train student with confidence-masked knowledge distillation\n",
    "    \"\"\"\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    kd_loss_fn = ConfidenceMaskedKnowledgeDistillation(\n",
    "        temperature=temperature,\n",
    "        alpha=alpha, \n",
    "        masking_strength=masking_strength\n",
    "    )\n",
    "    \n",
    "    epoch_stats = {'total_loss': 0, 'ce_loss': 0, 'kd_loss': 0}\n",
    "    \n",
    "    for  data, targets, batch_idx in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher_model(data)\n",
    "        \n",
    "        student_logits = student_model(data)\n",
    "        \n",
    "        # Calculate loss with confidence masking applied to teacher logits\n",
    "        total_loss, ce_loss, kd_loss = kd_loss_fn(student_logits, teacher_logits, targets)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        epoch_stats['total_loss'] += total_loss.item()\n",
    "        epoch_stats['ce_loss'] += ce_loss.item()\n",
    "        epoch_stats['kd_loss'] += kd_loss.item()\n",
    "        \n",
    "            \n",
    "    for key in epoch_stats:\n",
    "        epoch_stats[key] /= len(train_loader)\n",
    "    \n",
    "    return epoch_stats\n",
    "\n",
    "def evaluate_masking_effect(model, data_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets, _indices in data_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs).squeeze(-1).squeeze(-1)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct_idx = predicted.eq(targets.data).cpu()\n",
    "                correct += correct_idx.sum()\n",
    "\n",
    "        acc = 100. * float(correct) / float(total)\n",
    "        print('test acc:', acc)\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6663b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 21435\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "train_transform = prepare_transform(config['dataset'], config['arch'], config['augment'])\n",
    "plain_transform = prepare_transform(config['dataset'], config['arch'])\n",
    "\n",
    "train_superset = get_trainset(config['dataset'], train_transform)\n",
    "testset = get_testset(config['dataset'], plain_transform)\n",
    "\n",
    "num_classes = get_num_classes(config['dataset'])\n",
    "\n",
    "\n",
    "trainset = Subset(train_superset, saves['trained_on_indices'])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=config['batchsize'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=config['batchsize'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd9936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    # set random seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 2546\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ce2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"trained_models/models/test_kd\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27de6e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "test acc: 83.53\n",
      "Epoch 1 - Total Loss: 0.7916, CE Loss: 0.2274, KD Loss: 1.0334\n",
      "Epoch 1 - Test Accuracy: 83.53%\n",
      "Saved model with accuracy 83.53 at epoch 0\n",
      "\n",
      "Epoch 2\n",
      "test acc: 83.85\n",
      "Epoch 2 - Total Loss: 0.7318, CE Loss: 0.1962, KD Loss: 0.9613\n",
      "Epoch 2 - Test Accuracy: 83.85%\n",
      "\n",
      "Epoch 3\n",
      "test acc: 83.11\n",
      "Epoch 3 - Total Loss: 0.6924, CE Loss: 0.1872, KD Loss: 0.9089\n",
      "Epoch 3 - Test Accuracy: 83.11%\n",
      "\n",
      "Epoch 4\n",
      "test acc: 82.61\n",
      "Epoch 4 - Total Loss: 0.6787, CE Loss: 0.1781, KD Loss: 0.8932\n",
      "Epoch 4 - Test Accuracy: 82.61%\n",
      "\n",
      "Epoch 5\n",
      "test acc: 84.49\n",
      "Epoch 5 - Total Loss: 0.6564, CE Loss: 0.1749, KD Loss: 0.8628\n",
      "Epoch 5 - Test Accuracy: 84.49%\n",
      "\n",
      "Epoch 6\n",
      "test acc: 83.73\n",
      "Epoch 6 - Total Loss: 0.6133, CE Loss: 0.1546, KD Loss: 0.8098\n",
      "Epoch 6 - Test Accuracy: 83.73%\n",
      "Saved model with accuracy 83.73 at epoch 5\n",
      "\n",
      "Epoch 7\n",
      "test acc: 84.92\n",
      "Epoch 7 - Total Loss: 0.5958, CE Loss: 0.1504, KD Loss: 0.7867\n",
      "Epoch 7 - Test Accuracy: 84.92%\n",
      "\n",
      "Epoch 8\n",
      "test acc: 84.27\n",
      "Epoch 8 - Total Loss: 0.5912, CE Loss: 0.1508, KD Loss: 0.7799\n",
      "Epoch 8 - Test Accuracy: 84.27%\n",
      "\n",
      "Epoch 9\n",
      "test acc: 83.9\n",
      "Epoch 9 - Total Loss: 0.5591, CE Loss: 0.1447, KD Loss: 0.7367\n",
      "Epoch 9 - Test Accuracy: 83.90%\n",
      "\n",
      "Epoch 10\n",
      "test acc: 85.04\n",
      "Epoch 10 - Total Loss: 0.5468, CE Loss: 0.1335, KD Loss: 0.7238\n",
      "Epoch 10 - Test Accuracy: 85.04%\n",
      "\n",
      "Epoch 11\n",
      "test acc: 84.99\n",
      "Epoch 11 - Total Loss: 0.5183, CE Loss: 0.1233, KD Loss: 0.6875\n",
      "Epoch 11 - Test Accuracy: 84.99%\n",
      "Saved model with accuracy 84.99 at epoch 10\n",
      "\n",
      "Epoch 12\n",
      "test acc: 84.93\n",
      "Epoch 12 - Total Loss: 0.4854, CE Loss: 0.1097, KD Loss: 0.6465\n",
      "Epoch 12 - Test Accuracy: 84.93%\n",
      "\n",
      "Epoch 13\n",
      "test acc: 84.3\n",
      "Epoch 13 - Total Loss: 0.4811, CE Loss: 0.1095, KD Loss: 0.6403\n",
      "Epoch 13 - Test Accuracy: 84.30%\n",
      "\n",
      "Epoch 14\n",
      "test acc: 85.91\n",
      "Epoch 14 - Total Loss: 0.4767, CE Loss: 0.1110, KD Loss: 0.6334\n",
      "Epoch 14 - Test Accuracy: 85.91%\n",
      "\n",
      "Epoch 15\n",
      "test acc: 85.71\n",
      "Epoch 15 - Total Loss: 0.4628, CE Loss: 0.1058, KD Loss: 0.6158\n",
      "Epoch 15 - Test Accuracy: 85.71%\n",
      "\n",
      "Epoch 16\n",
      "test acc: 84.24\n",
      "Epoch 16 - Total Loss: 0.4506, CE Loss: 0.0984, KD Loss: 0.6016\n",
      "Epoch 16 - Test Accuracy: 84.24%\n",
      "\n",
      "Epoch 17\n",
      "test acc: 85.44\n",
      "Epoch 17 - Total Loss: 0.4430, CE Loss: 0.0968, KD Loss: 0.5914\n",
      "Epoch 17 - Test Accuracy: 85.44%\n",
      "\n",
      "Epoch 18\n",
      "test acc: 85.27\n",
      "Epoch 18 - Total Loss: 0.4117, CE Loss: 0.0870, KD Loss: 0.5508\n",
      "Epoch 18 - Test Accuracy: 85.27%\n",
      "\n",
      "Epoch 19\n",
      "test acc: 84.95\n",
      "Epoch 19 - Total Loss: 0.4318, CE Loss: 0.0957, KD Loss: 0.5759\n",
      "Epoch 19 - Test Accuracy: 84.95%\n",
      "\n",
      "Epoch 20\n",
      "test acc: 85.19\n",
      "Epoch 20 - Total Loss: 0.4105, CE Loss: 0.0861, KD Loss: 0.5496\n",
      "Epoch 20 - Test Accuracy: 85.19%\n",
      "\n",
      "Epoch 21\n",
      "test acc: 85.85\n",
      "Epoch 21 - Total Loss: 0.3917, CE Loss: 0.0785, KD Loss: 0.5260\n",
      "Epoch 21 - Test Accuracy: 85.85%\n",
      "Saved model with accuracy 85.85 at epoch 20\n",
      "\n",
      "Epoch 22\n",
      "test acc: 86.11\n",
      "Epoch 22 - Total Loss: 0.3985, CE Loss: 0.0850, KD Loss: 0.5329\n",
      "Epoch 22 - Test Accuracy: 86.11%\n",
      "\n",
      "Epoch 23\n",
      "test acc: 85.43\n",
      "Epoch 23 - Total Loss: 0.3787, CE Loss: 0.0778, KD Loss: 0.5077\n",
      "Epoch 23 - Test Accuracy: 85.43%\n",
      "\n",
      "Epoch 24\n",
      "test acc: 85.3\n",
      "Epoch 24 - Total Loss: 0.3757, CE Loss: 0.0741, KD Loss: 0.5049\n",
      "Epoch 24 - Test Accuracy: 85.30%\n",
      "\n",
      "Epoch 25\n",
      "test acc: 85.14\n",
      "Epoch 25 - Total Loss: 0.3716, CE Loss: 0.0748, KD Loss: 0.4988\n",
      "Epoch 25 - Test Accuracy: 85.14%\n",
      "\n",
      "Epoch 26\n",
      "test acc: 85.12\n",
      "Epoch 26 - Total Loss: 0.3614, CE Loss: 0.0715, KD Loss: 0.4857\n",
      "Epoch 26 - Test Accuracy: 85.12%\n",
      "\n",
      "Epoch 27\n",
      "test acc: 85.84\n",
      "Epoch 27 - Total Loss: 0.3558, CE Loss: 0.0728, KD Loss: 0.4772\n",
      "Epoch 27 - Test Accuracy: 85.84%\n",
      "\n",
      "Epoch 28\n",
      "test acc: 86.26\n",
      "Epoch 28 - Total Loss: 0.3492, CE Loss: 0.0689, KD Loss: 0.4694\n",
      "Epoch 28 - Test Accuracy: 86.26%\n",
      "\n",
      "Epoch 29\n",
      "test acc: 85.85\n",
      "Epoch 29 - Total Loss: 0.3412, CE Loss: 0.0679, KD Loss: 0.4583\n",
      "Epoch 29 - Test Accuracy: 85.85%\n",
      "\n",
      "Epoch 30\n",
      "test acc: 86.45\n",
      "Epoch 30 - Total Loss: 0.3324, CE Loss: 0.0581, KD Loss: 0.4499\n",
      "Epoch 30 - Test Accuracy: 86.45%\n",
      "\n",
      "Epoch 31\n",
      "test acc: 85.73\n",
      "Epoch 31 - Total Loss: 0.3385, CE Loss: 0.0649, KD Loss: 0.4558\n",
      "Epoch 31 - Test Accuracy: 85.73%\n",
      "\n",
      "Epoch 32\n",
      "test acc: 86.46\n",
      "Epoch 32 - Total Loss: 0.3323, CE Loss: 0.0613, KD Loss: 0.4484\n",
      "Epoch 32 - Test Accuracy: 86.46%\n",
      "\n",
      "Epoch 33\n",
      "test acc: 86.16\n",
      "Epoch 33 - Total Loss: 0.3264, CE Loss: 0.0616, KD Loss: 0.4399\n",
      "Epoch 33 - Test Accuracy: 86.16%\n",
      "\n",
      "Epoch 34\n",
      "test acc: 85.71\n",
      "Epoch 34 - Total Loss: 0.3144, CE Loss: 0.0556, KD Loss: 0.4253\n",
      "Epoch 34 - Test Accuracy: 85.71%\n",
      "\n",
      "Epoch 35\n",
      "test acc: 86.15\n",
      "Epoch 35 - Total Loss: 0.3131, CE Loss: 0.0571, KD Loss: 0.4228\n",
      "Epoch 35 - Test Accuracy: 86.15%\n",
      "\n",
      "Epoch 36\n",
      "test acc: 86.65\n",
      "Epoch 36 - Total Loss: 0.3133, CE Loss: 0.0555, KD Loss: 0.4237\n",
      "Epoch 36 - Test Accuracy: 86.65%\n",
      "Saved model with accuracy 86.65 at epoch 35\n",
      "\n",
      "Epoch 37\n",
      "test acc: 86.02\n",
      "Epoch 37 - Total Loss: 0.3295, CE Loss: 0.0650, KD Loss: 0.4429\n",
      "Epoch 37 - Test Accuracy: 86.02%\n",
      "\n",
      "Epoch 38\n",
      "test acc: 86.51\n",
      "Epoch 38 - Total Loss: 0.2969, CE Loss: 0.0494, KD Loss: 0.4030\n",
      "Epoch 38 - Test Accuracy: 86.51%\n",
      "\n",
      "Epoch 39\n",
      "test acc: 86.3\n",
      "Epoch 39 - Total Loss: 0.3018, CE Loss: 0.0514, KD Loss: 0.4090\n",
      "Epoch 39 - Test Accuracy: 86.30%\n",
      "\n",
      "Epoch 40\n",
      "test acc: 86.09\n",
      "Epoch 40 - Total Loss: 0.2859, CE Loss: 0.0459, KD Loss: 0.3887\n",
      "Epoch 40 - Test Accuracy: 86.09%\n",
      "\n",
      "Epoch 41\n",
      "test acc: 86.76\n",
      "Epoch 41 - Total Loss: 0.3031, CE Loss: 0.0556, KD Loss: 0.4092\n",
      "Epoch 41 - Test Accuracy: 86.76%\n",
      "Saved model with accuracy 86.76 at epoch 40\n",
      "\n",
      "Epoch 42\n",
      "test acc: 86.22\n",
      "Epoch 42 - Total Loss: 0.2956, CE Loss: 0.0505, KD Loss: 0.4007\n",
      "Epoch 42 - Test Accuracy: 86.22%\n",
      "\n",
      "Epoch 43\n",
      "test acc: 86.64\n",
      "Epoch 43 - Total Loss: 0.2782, CE Loss: 0.0452, KD Loss: 0.3780\n",
      "Epoch 43 - Test Accuracy: 86.64%\n",
      "\n",
      "Epoch 44\n",
      "test acc: 86.08\n",
      "Epoch 44 - Total Loss: 0.2659, CE Loss: 0.0418, KD Loss: 0.3619\n",
      "Epoch 44 - Test Accuracy: 86.08%\n",
      "\n",
      "Epoch 45\n",
      "test acc: 85.93\n",
      "Epoch 45 - Total Loss: 0.2904, CE Loss: 0.0501, KD Loss: 0.3934\n",
      "Epoch 45 - Test Accuracy: 85.93%\n",
      "\n",
      "Epoch 46\n",
      "test acc: 86.5\n",
      "Epoch 46 - Total Loss: 0.2841, CE Loss: 0.0484, KD Loss: 0.3851\n",
      "Epoch 46 - Test Accuracy: 86.50%\n",
      "\n",
      "Epoch 47\n",
      "test acc: 86.56\n",
      "Epoch 47 - Total Loss: 0.2731, CE Loss: 0.0441, KD Loss: 0.3713\n",
      "Epoch 47 - Test Accuracy: 86.56%\n",
      "\n",
      "Epoch 48\n",
      "test acc: 86.58\n",
      "Epoch 48 - Total Loss: 0.2722, CE Loss: 0.0422, KD Loss: 0.3707\n",
      "Epoch 48 - Test Accuracy: 86.58%\n",
      "\n",
      "Epoch 49\n",
      "test acc: 86.88\n",
      "Epoch 49 - Total Loss: 0.2755, CE Loss: 0.0452, KD Loss: 0.3742\n",
      "Epoch 49 - Test Accuracy: 86.88%\n",
      "\n",
      "Epoch 50\n",
      "test acc: 86.52\n",
      "Epoch 50 - Total Loss: 0.2515, CE Loss: 0.0357, KD Loss: 0.3440\n",
      "Epoch 50 - Test Accuracy: 86.52%\n",
      "\n",
      "Epoch 51\n",
      "test acc: 86.46\n",
      "Epoch 51 - Total Loss: 0.2647, CE Loss: 0.0429, KD Loss: 0.3597\n",
      "Epoch 51 - Test Accuracy: 86.46%\n",
      "\n",
      "Epoch 52\n",
      "test acc: 86.49\n",
      "Epoch 52 - Total Loss: 0.2564, CE Loss: 0.0397, KD Loss: 0.3493\n",
      "Epoch 52 - Test Accuracy: 86.49%\n",
      "\n",
      "Epoch 53\n",
      "test acc: 86.98\n",
      "Epoch 53 - Total Loss: 0.2620, CE Loss: 0.0419, KD Loss: 0.3563\n",
      "Epoch 53 - Test Accuracy: 86.98%\n",
      "\n",
      "Epoch 54\n",
      "test acc: 86.62\n",
      "Epoch 54 - Total Loss: 0.2573, CE Loss: 0.0384, KD Loss: 0.3511\n",
      "Epoch 54 - Test Accuracy: 86.62%\n",
      "\n",
      "Epoch 55\n",
      "test acc: 86.56\n",
      "Epoch 55 - Total Loss: 0.2402, CE Loss: 0.0321, KD Loss: 0.3294\n",
      "Epoch 55 - Test Accuracy: 86.56%\n",
      "\n",
      "Epoch 56\n",
      "test acc: 86.75\n",
      "Epoch 56 - Total Loss: 0.2491, CE Loss: 0.0394, KD Loss: 0.3389\n",
      "Epoch 56 - Test Accuracy: 86.75%\n",
      "\n",
      "Epoch 57\n",
      "test acc: 86.57\n",
      "Epoch 57 - Total Loss: 0.2582, CE Loss: 0.0440, KD Loss: 0.3500\n",
      "Epoch 57 - Test Accuracy: 86.57%\n",
      "\n",
      "Epoch 58\n",
      "test acc: 86.79\n",
      "Epoch 58 - Total Loss: 0.2412, CE Loss: 0.0362, KD Loss: 0.3291\n",
      "Epoch 58 - Test Accuracy: 86.79%\n",
      "\n",
      "Epoch 59\n",
      "test acc: 86.72\n",
      "Epoch 59 - Total Loss: 0.2441, CE Loss: 0.0364, KD Loss: 0.3331\n",
      "Epoch 59 - Test Accuracy: 86.72%\n",
      "\n",
      "Epoch 60\n",
      "test acc: 87.17\n",
      "Epoch 60 - Total Loss: 0.2452, CE Loss: 0.0365, KD Loss: 0.3347\n",
      "Epoch 60 - Test Accuracy: 87.17%\n",
      "\n",
      "Epoch 61\n",
      "test acc: 86.66\n",
      "Epoch 61 - Total Loss: 0.2344, CE Loss: 0.0344, KD Loss: 0.3200\n",
      "Epoch 61 - Test Accuracy: 86.66%\n",
      "\n",
      "Epoch 62\n",
      "test acc: 87.33\n",
      "Epoch 62 - Total Loss: 0.2489, CE Loss: 0.0399, KD Loss: 0.3385\n",
      "Epoch 62 - Test Accuracy: 87.33%\n",
      "\n",
      "Epoch 63\n",
      "test acc: 86.73\n",
      "Epoch 63 - Total Loss: 0.2328, CE Loss: 0.0312, KD Loss: 0.3193\n",
      "Epoch 63 - Test Accuracy: 86.73%\n",
      "\n",
      "Epoch 64\n",
      "test acc: 87.09\n",
      "Epoch 64 - Total Loss: 0.2252, CE Loss: 0.0346, KD Loss: 0.3070\n",
      "Epoch 64 - Test Accuracy: 87.09%\n",
      "\n",
      "Epoch 65\n",
      "test acc: 86.99\n",
      "Epoch 65 - Total Loss: 0.2341, CE Loss: 0.0318, KD Loss: 0.3208\n",
      "Epoch 65 - Test Accuracy: 86.99%\n",
      "\n",
      "Epoch 66\n",
      "test acc: 87.35\n",
      "Epoch 66 - Total Loss: 0.2332, CE Loss: 0.0351, KD Loss: 0.3181\n",
      "Epoch 66 - Test Accuracy: 87.35%\n",
      "Saved model with accuracy 87.35 at epoch 65\n",
      "\n",
      "Epoch 67\n",
      "test acc: 87.77\n",
      "Epoch 67 - Total Loss: 0.2287, CE Loss: 0.0334, KD Loss: 0.3123\n",
      "Epoch 67 - Test Accuracy: 87.77%\n",
      "\n",
      "Epoch 68\n",
      "test acc: 87.55\n",
      "Epoch 68 - Total Loss: 0.2247, CE Loss: 0.0313, KD Loss: 0.3075\n",
      "Epoch 68 - Test Accuracy: 87.55%\n",
      "\n",
      "Epoch 69\n",
      "test acc: 86.61\n",
      "Epoch 69 - Total Loss: 0.2247, CE Loss: 0.0314, KD Loss: 0.3076\n",
      "Epoch 69 - Test Accuracy: 86.61%\n",
      "\n",
      "Epoch 70\n",
      "test acc: 87.36\n",
      "Epoch 70 - Total Loss: 0.2271, CE Loss: 0.0334, KD Loss: 0.3101\n",
      "Epoch 70 - Test Accuracy: 87.36%\n",
      "\n",
      "Epoch 71\n",
      "test acc: 87.42\n",
      "Epoch 71 - Total Loss: 0.2196, CE Loss: 0.0306, KD Loss: 0.3006\n",
      "Epoch 71 - Test Accuracy: 87.42%\n",
      "Saved model with accuracy 87.42 at epoch 70\n",
      "\n",
      "Epoch 72\n",
      "test acc: 86.87\n",
      "Epoch 72 - Total Loss: 0.2161, CE Loss: 0.0282, KD Loss: 0.2966\n",
      "Epoch 72 - Test Accuracy: 86.87%\n",
      "\n",
      "Epoch 73\n",
      "test acc: 87.12\n",
      "Epoch 73 - Total Loss: 0.2201, CE Loss: 0.0295, KD Loss: 0.3018\n",
      "Epoch 73 - Test Accuracy: 87.12%\n",
      "\n",
      "Epoch 74\n",
      "test acc: 86.87\n",
      "Epoch 74 - Total Loss: 0.2181, CE Loss: 0.0290, KD Loss: 0.2992\n",
      "Epoch 74 - Test Accuracy: 86.87%\n",
      "\n",
      "Epoch 75\n",
      "test acc: 86.48\n",
      "Epoch 75 - Total Loss: 0.2199, CE Loss: 0.0302, KD Loss: 0.3012\n",
      "Epoch 75 - Test Accuracy: 86.48%\n",
      "\n",
      "Epoch 76\n",
      "test acc: 87.37\n",
      "Epoch 76 - Total Loss: 0.2190, CE Loss: 0.0320, KD Loss: 0.2991\n",
      "Epoch 76 - Test Accuracy: 87.37%\n",
      "\n",
      "Epoch 77\n",
      "test acc: 87.2\n",
      "Epoch 77 - Total Loss: 0.2103, CE Loss: 0.0307, KD Loss: 0.2873\n",
      "Epoch 77 - Test Accuracy: 87.20%\n",
      "\n",
      "Epoch 78\n",
      "test acc: 86.81\n",
      "Epoch 78 - Total Loss: 0.2130, CE Loss: 0.0299, KD Loss: 0.2916\n",
      "Epoch 78 - Test Accuracy: 86.81%\n",
      "\n",
      "Epoch 79\n",
      "test acc: 87.39\n",
      "Epoch 79 - Total Loss: 0.2026, CE Loss: 0.0253, KD Loss: 0.2785\n",
      "Epoch 79 - Test Accuracy: 87.39%\n",
      "\n",
      "Epoch 80\n",
      "test acc: 87.26\n",
      "Epoch 80 - Total Loss: 0.2052, CE Loss: 0.0288, KD Loss: 0.2807\n",
      "Epoch 80 - Test Accuracy: 87.26%\n",
      "\n",
      "Epoch 81\n",
      "test acc: 87.34\n",
      "Epoch 81 - Total Loss: 0.2190, CE Loss: 0.0342, KD Loss: 0.2981\n",
      "Epoch 81 - Test Accuracy: 87.34%\n",
      "\n",
      "Epoch 82\n",
      "test acc: 86.61\n",
      "Epoch 82 - Total Loss: 0.2073, CE Loss: 0.0289, KD Loss: 0.2838\n",
      "Epoch 82 - Test Accuracy: 86.61%\n",
      "\n",
      "Epoch 83\n",
      "test acc: 87.23\n",
      "Epoch 83 - Total Loss: 0.2012, CE Loss: 0.0260, KD Loss: 0.2763\n",
      "Epoch 83 - Test Accuracy: 87.23%\n",
      "\n",
      "Epoch 84\n",
      "test acc: 86.73\n",
      "Epoch 84 - Total Loss: 0.1987, CE Loss: 0.0259, KD Loss: 0.2728\n",
      "Epoch 84 - Test Accuracy: 86.73%\n",
      "\n",
      "Epoch 85\n",
      "test acc: 86.86\n",
      "Epoch 85 - Total Loss: 0.1997, CE Loss: 0.0267, KD Loss: 0.2738\n",
      "Epoch 85 - Test Accuracy: 86.86%\n",
      "\n",
      "Epoch 86\n",
      "test acc: 87.52\n",
      "Epoch 86 - Total Loss: 0.2005, CE Loss: 0.0258, KD Loss: 0.2754\n",
      "Epoch 86 - Test Accuracy: 87.52%\n",
      "Saved model with accuracy 87.52 at epoch 85\n",
      "\n",
      "Epoch 87\n",
      "test acc: 87.31\n",
      "Epoch 87 - Total Loss: 0.2034, CE Loss: 0.0289, KD Loss: 0.2782\n",
      "Epoch 87 - Test Accuracy: 87.31%\n",
      "\n",
      "Epoch 88\n",
      "test acc: 86.92\n",
      "Epoch 88 - Total Loss: 0.1983, CE Loss: 0.0278, KD Loss: 0.2713\n",
      "Epoch 88 - Test Accuracy: 86.92%\n",
      "\n",
      "Epoch 89\n",
      "test acc: 87.39\n",
      "Epoch 89 - Total Loss: 0.2028, CE Loss: 0.0283, KD Loss: 0.2776\n",
      "Epoch 89 - Test Accuracy: 87.39%\n",
      "\n",
      "Epoch 90\n",
      "test acc: 87.01\n",
      "Epoch 90 - Total Loss: 0.1925, CE Loss: 0.0253, KD Loss: 0.2641\n",
      "Epoch 90 - Test Accuracy: 87.01%\n",
      "\n",
      "Epoch 91\n",
      "test acc: 87.15\n",
      "Epoch 91 - Total Loss: 0.1869, CE Loss: 0.0218, KD Loss: 0.2576\n",
      "Epoch 91 - Test Accuracy: 87.15%\n",
      "\n",
      "Epoch 92\n",
      "test acc: 87.49\n",
      "Epoch 92 - Total Loss: 0.2067, CE Loss: 0.0315, KD Loss: 0.2818\n",
      "Epoch 92 - Test Accuracy: 87.49%\n",
      "\n",
      "Epoch 93\n",
      "test acc: 87.39\n",
      "Epoch 93 - Total Loss: 0.1997, CE Loss: 0.0274, KD Loss: 0.2736\n",
      "Epoch 93 - Test Accuracy: 87.39%\n",
      "\n",
      "Epoch 94\n",
      "test acc: 87.74\n",
      "Epoch 94 - Total Loss: 0.1870, CE Loss: 0.0243, KD Loss: 0.2568\n",
      "Epoch 94 - Test Accuracy: 87.74%\n",
      "\n",
      "Epoch 95\n",
      "test acc: 87.33\n",
      "Epoch 95 - Total Loss: 0.1884, CE Loss: 0.0249, KD Loss: 0.2584\n",
      "Epoch 95 - Test Accuracy: 87.33%\n",
      "\n",
      "Epoch 96\n",
      "test acc: 87.57\n",
      "Epoch 96 - Total Loss: 0.1942, CE Loss: 0.0250, KD Loss: 0.2667\n",
      "Epoch 96 - Test Accuracy: 87.57%\n",
      "Saved model with accuracy 87.57 at epoch 95\n",
      "\n",
      "Epoch 97\n",
      "test acc: 87.55\n",
      "Epoch 97 - Total Loss: 0.1818, CE Loss: 0.0212, KD Loss: 0.2507\n",
      "Epoch 97 - Test Accuracy: 87.55%\n",
      "\n",
      "Epoch 98\n",
      "test acc: 86.43\n",
      "Epoch 98 - Total Loss: 0.1902, CE Loss: 0.0243, KD Loss: 0.2613\n",
      "Epoch 98 - Test Accuracy: 86.43%\n",
      "\n",
      "Epoch 99\n",
      "test acc: 87.19\n",
      "Epoch 99 - Total Loss: 0.1855, CE Loss: 0.0233, KD Loss: 0.2550\n",
      "Epoch 99 - Test Accuracy: 87.19%\n",
      "\n",
      "Epoch 100\n",
      "test acc: 87.54\n",
      "Epoch 100 - Total Loss: 0.1944, CE Loss: 0.0289, KD Loss: 0.2653\n",
      "Epoch 100 - Test Accuracy: 87.54%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    \n",
    "    # Train with different masking strengths\n",
    "    stats = train_with_confidence_masked_kd(\n",
    "        teacher_model=teacher,\n",
    "        student_model=student, \n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=config[\"device\"],\n",
    "        temperature=3.0,\n",
    "        alpha=0.7,  # Balance between CE and KD\n",
    "        masking_strength=0  # How much to randomize confidence\n",
    "    )\n",
    "    results = evaluate_masking_effect(student, test_loader, config[\"device\"])\n",
    "    print(f\"Epoch {epoch+1} - Total Loss: {stats['total_loss']:.4f}, CE Loss: {stats['ce_loss']:.4f}, KD Loss: {stats['kd_loss']:.4f}\")\n",
    "    print(f\"Epoch {epoch+1} - Test Accuracy: {results:.2f}%\")\n",
    "    if epoch%5 == 0:\n",
    "        if results > acc:\n",
    "            acc = results\n",
    "            dict = {\n",
    "                'model_state_dict': student.state_dict(),\n",
    "                'trained_on_indices': saves['trained_on_indices'],\n",
    "                'arch': config['arch'],\n",
    "                'seed' : seed,\n",
    "                'hyperparameters': saves['hyperparameters'],\n",
    "                'dataset': config['dataset'],\n",
    "                'temperature': 3.0,\n",
    "                'masking_strength': 0.5,\n",
    "                'alpha': 0.7,\n",
    "                'test_acc': results\n",
    "            }\n",
    "            torch.save(dict, f\"trained_models/models/test_kd/epoch_{epoch}_acc_{acc}.pt\")\n",
    "            print(f\"Saved model with accuracy {acc} at epoch {epoch}\")\n",
    "\n",
    "    #     acc = results\n",
    "    #     dict = {\n",
    "    #         'model_state_dict': student.state_dict(),\n",
    "    #         'trained_on_indices': teacher_saves['trained_on_indices'],\n",
    "    #         'arch': config['arch'],\n",
    "    #         'seed' : seed,\n",
    "    #         'hyperparameters': saves['hyperparameters'],\n",
    "    #         'dataset': config['dataset'],\n",
    "    #         'temperature': 3.0,\n",
    "    #         'masking_strength': 0.5,\n",
    "    #         'alpha': 0.7,\n",
    "    #         'test_acc': results\n",
    "    #     }\n",
    "    #     torch.save(dict, f\"trained_models/models/test_kd/epoch_{epoch}_acc_{acc}.pt\")\n",
    "    #     print(f\"Saved model with accuracy {acc} at epoch {epoch}\")\n",
    "    # else:\n",
    "    #     print(f\"Model did not improve at epoch {epoch}, current best accuracy: {acc}\")\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b1b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_models/models/kd/target\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dict = {\n",
    "    'model_state_dict': student.state_dict(),\n",
    "    'trained_on_indices': teacher_saves['trained_on_indices'],\n",
    "    'arch': config['arch'],\n",
    "    'seed' : seed,\n",
    "    'hyperparameters': saves['hyperparameters'],\n",
    "    'dataset': config['dataset'],\n",
    "    'temperature': 3.0,\n",
    "    'masking_strength': 0,\n",
    "    'alpha': 0.7,\n",
    "    'test_acc': results\n",
    "}\n",
    "path = f\"{MODEL_DIR}/models/kd/target\"\n",
    "if not os.path.exists(os.path.dirname(path)):\n",
    "    os.makedirs(os.path.dirname(path))\n",
    "\n",
    "torch.save(dict, path)\n",
    "print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a979f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Attack Pipeline for experiment: kd\n",
      "Architecture: wrn28-2, Dataset: CIFAR10\n",
      "Shadow models: 64, GPU: CPU\n",
      "Model directory: trained_models/models/kd\n",
      "Storage directory: trained_models\n",
      "\n",
      "============================================================\n",
      "STARTING: Running LiRA attack on kd\n",
      "Command: python3 -m loss_traces.attacks --exp_id kd --attack LiRA --arch wrn28-2 --dataset CIFAR10 --gpu  --target_id target --n_shadows 32 --layer 0 --layer_folder None\n",
      "============================================================\n",
      "agument=True, arch=wrn28-2, dataset=CIFAR10\n",
      "/vol/bitbucket/vb524/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Dataset size: 50000\n",
      "No intermediate results found at trained_models/scaled_logits_intermediate/kd.pt. Computing intermediate results...\n",
      "Computing all metrics...\n",
      "Computed metrics for shadow 0\n",
      "Computed metrics for shadow 1\n",
      "Computed metrics for shadow 2\n",
      "Computed metrics for shadow 3\n",
      "Computed metrics for shadow 4\n",
      "Computed metrics for shadow 5\n",
      "Computed metrics for shadow 6\n",
      "Computed metrics for shadow 7\n",
      "Computed metrics for shadow 8\n",
      "Computed metrics for shadow 9\n",
      "Computed metrics for shadow 10\n",
      "Computed metrics for shadow 11\n",
      "Computed metrics for shadow 12\n",
      "Computed metrics for shadow 13\n",
      "Computed metrics for shadow 14\n",
      "Computed metrics for shadow 15\n",
      "Computed metrics for shadow 16\n",
      "Computed metrics for shadow 17\n",
      "Computed metrics for shadow 18\n",
      "Computed metrics for shadow 19\n",
      "Computed metrics for shadow 20\n",
      "Computed metrics for shadow 21\n",
      "Computed metrics for shadow 22\n",
      "Computed metrics for shadow 23\n",
      "Computed metrics for shadow 24\n",
      "Computed metrics for shadow 25\n",
      "Computed metrics for shadow 26\n",
      "Computed metrics for shadow 27\n",
      "Computed metrics for shadow 28\n",
      "Computed metrics for shadow 29\n",
      "Computed metrics for shadow 30\n",
      "Computed metrics for shadow 31\n",
      "Computed metrics for shadow 32\n",
      "Computed metrics for shadow 33\n",
      "Computed metrics for shadow 34\n",
      "Computed metrics for shadow 35\n",
      "Computed metrics for shadow 36\n",
      "Computed metrics for shadow 37\n",
      "Computed metrics for shadow 38\n",
      "Computed metrics for shadow 39\n",
      "Computed metrics for shadow 40\n",
      "Computed metrics for shadow 41\n",
      "Computed metrics for shadow 42\n",
      "Computed metrics for shadow 43\n",
      "Computed metrics for shadow 44\n",
      "Computed metrics for shadow 45\n",
      "Computed metrics for shadow 46\n",
      "Computed metrics for shadow 47\n",
      "Computed metrics for shadow 48\n",
      "Computed metrics for shadow 49\n",
      "Computed metrics for shadow 50\n",
      "Computed metrics for shadow 51\n",
      "Computed metrics for shadow 52\n",
      "Computed metrics for shadow 53\n",
      "Computed metrics for shadow 54\n",
      "Computed metrics for shadow 55\n",
      "Computed metrics for shadow 56\n",
      "Computed metrics for shadow 57\n",
      "Computed metrics for shadow 58\n",
      "Computed metrics for shadow 59\n",
      "Computed metrics for shadow 60\n",
      "Computed metrics for shadow 61\n",
      "Computed metrics for shadow 62\n",
      "Computed metrics for shadow 63\n",
      "Computing statistics for losses...\n",
      "Computing statistics for logits...\n",
      "Computing statistics for scaled_logits...\n",
      "Computing statistics for target_logits...\n",
      "Performance Timings:\n",
      "Total computation time: 1353.69s\n",
      "Finished stats\n",
      "target_confs shape: (50000, 2), in_means shape: 50000, out_means shape: 50000\n",
      "[[28.56592169 24.59477441]\n",
      " [24.59477441 28.61039303]]\n",
      "Attack AUC: 0.5859460752000001\n",
      "✅ SUCCESS: Running LiRA attack on kd completed in 1465.32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', '-m', 'src.loss_traces.run_attack_pipeline', '--exp_id', 'kd', '--target', 'target', '--arch', 'wrn28-2', '--dataset', 'CIFAR10', '--lira-only', '--layer', '0'], returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recompute lira\n",
    "import subprocess\n",
    "subprocess.run([ \"python\", \"-m\", \"src.loss_traces.run_attack_pipeline\",\n",
    "    \"--exp_id\", \"kd\",\n",
    "    \"--target\", \"target\",\n",
    "    \"--arch\", \"wrn28-2\",\n",
    "    \"--dataset\", \"CIFAR10\",\n",
    "    \"--lira-only\",\n",
    "    \"--layer\", \"0\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d997061",
   "metadata": {},
   "source": [
    "## 0 Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33251d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Epoch stats: {'total_loss': 2.6427344292764547, 'ce_loss': 0.9679769947189392, 'kd_loss': 3.3604876547384475}\n",
      "\n",
      "Epoch 2\n",
      "Epoch stats: {'total_loss': 1.9661887448259598, 'ce_loss': 0.7216846397705495, 'kd_loss': 2.499547674308125}\n",
      "\n",
      "Epoch 3\n",
      "Epoch stats: {'total_loss': 1.7237788391128535, 'ce_loss': 0.6312054941205455, 'kd_loss': 2.1920245812248895}\n",
      "\n",
      "Epoch 4\n",
      "Epoch stats: {'total_loss': 1.549623906555194, 'ce_loss': 0.5790883142594069, 'kd_loss': 1.9655677521373702}\n",
      "\n",
      "Epoch 5\n",
      "Epoch stats: {'total_loss': 1.4271465303115332, 'ce_loss': 0.5295255353301287, 'kd_loss': 1.811841260601295}\n",
      "\n",
      "Epoch 6\n",
      "Epoch stats: {'total_loss': 1.3152549459967793, 'ce_loss': 0.4842796057506786, 'kd_loss': 1.6713872516643369}\n",
      "\n",
      "Epoch 7\n",
      "Epoch stats: {'total_loss': 1.215445734641526, 'ce_loss': 0.44351075715144056, 'kd_loss': 1.5462750258235236}\n",
      "\n",
      "Epoch 8\n",
      "Epoch stats: {'total_loss': 1.139014896269952, 'ce_loss': 0.4168308498516622, 'kd_loss': 1.4485223602958772}\n",
      "\n",
      "Epoch 9\n",
      "Epoch stats: {'total_loss': 1.0707332525147282, 'ce_loss': 0.3906243244467288, 'kd_loss': 1.3622085208779944}\n",
      "\n",
      "Epoch 10\n",
      "Epoch stats: {'total_loss': 1.0061762793679612, 'ce_loss': 0.3617717041559541, 'kd_loss': 1.2823496832537942}\n",
      "\n",
      "Evaluating masking effect on student model:\n",
      "test acc: 86.97\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    \n",
    "    # Train with different masking strengths\n",
    "    stats = train_with_confidence_masked_kd(\n",
    "        teacher_model=teacher,\n",
    "        student_model=student, \n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=config[\"device\"],\n",
    "        temperature=3.0,\n",
    "        alpha=0.7,  \n",
    "        masking_strength=0  \n",
    "    )\n",
    "    \n",
    "    print(f\"Epoch stats: {stats}\")\n",
    "\n",
    "# Evaluate the effect of masking on final model\n",
    "print(\"\\nEvaluating masking effect on student model:\")\n",
    "results = evaluate_masking_effect(student, test_loader, config[\"device\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f79525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_models/models/kd_0_mask/target\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dict = {\n",
    "    'model_state_dict': student.state_dict(),\n",
    "    'trained_on_indices': teacher_saves['trained_on_indices'],\n",
    "    'arch': config['arch'],\n",
    "    'seed' : seed,\n",
    "    'hyperparameters': saves['hyperparameters'],\n",
    "    'dataset': config['dataset'],\n",
    "    'temperature': 3.0,\n",
    "    'masking_strength': 0.5,\n",
    "    'alpha': 0.7,\n",
    "    'test_acc': results\n",
    "}\n",
    "path = f\"{MODEL_DIR}/models/kd_0_mask/target\"\n",
    "if not os.path.exists(os.path.dirname(path)):\n",
    "    os.makedirs(os.path.dirname(path))\n",
    "\n",
    "torch.save(dict, path)\n",
    "print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac207db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Attack Pipeline for experiment: kd_0_mask\n",
      "Architecture: wrn28-2, Dataset: CIFAR10\n",
      "Shadow models: 64, GPU: CPU\n",
      "Model directory: trained_models/models/kd_0_mask\n",
      "Storage directory: trained_models\n",
      "\n",
      "============================================================\n",
      "STARTING: Running LiRA attack on kd_0_mask\n",
      "Command: python3 -m loss_traces.attacks --exp_id kd_0_mask --attack LiRA --arch wrn28-2 --dataset CIFAR10 --gpu  --target_id target --n_shadows 32 --layer 0 --layer_folder None\n",
      "============================================================\n",
      "agument=True, arch=wrn28-2, dataset=CIFAR10\n",
      "/vol/bitbucket/vb524/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Dataset size: 50000\n",
      "No intermediate results found at trained_models/scaled_logits_intermediate/kd_0_mask.pt. Computing intermediate results...\n",
      "Computing all metrics...\n",
      "Computed metrics for shadow 0\n",
      "Computed metrics for shadow 1\n",
      "Computed metrics for shadow 2\n",
      "Computed metrics for shadow 3\n",
      "Computed metrics for shadow 4\n",
      "Computed metrics for shadow 5\n",
      "Computed metrics for shadow 6\n",
      "Computed metrics for shadow 7\n",
      "Computed metrics for shadow 8\n",
      "Computed metrics for shadow 9\n",
      "Computed metrics for shadow 10\n",
      "Computed metrics for shadow 11\n",
      "Computed metrics for shadow 12\n",
      "Computed metrics for shadow 13\n",
      "Computed metrics for shadow 14\n",
      "Computed metrics for shadow 15\n",
      "Computed metrics for shadow 16\n",
      "Computed metrics for shadow 17\n",
      "Computed metrics for shadow 18\n",
      "Computed metrics for shadow 19\n",
      "Computed metrics for shadow 20\n",
      "Computed metrics for shadow 21\n",
      "Computed metrics for shadow 22\n",
      "Computed metrics for shadow 23\n",
      "Computed metrics for shadow 24\n",
      "Computed metrics for shadow 25\n",
      "Computed metrics for shadow 26\n",
      "Computed metrics for shadow 27\n",
      "Computed metrics for shadow 28\n",
      "Computed metrics for shadow 29\n",
      "Computed metrics for shadow 30\n",
      "Computed metrics for shadow 31\n",
      "Computed metrics for shadow 32\n",
      "Computed metrics for shadow 33\n",
      "Computed metrics for shadow 34\n",
      "Computed metrics for shadow 35\n",
      "Computed metrics for shadow 36\n",
      "Computed metrics for shadow 37\n",
      "Computed metrics for shadow 38\n",
      "Computed metrics for shadow 39\n",
      "Computed metrics for shadow 40\n",
      "Computed metrics for shadow 41\n",
      "Computed metrics for shadow 42\n",
      "Computed metrics for shadow 43\n",
      "Computed metrics for shadow 44\n",
      "Computed metrics for shadow 45\n",
      "Computed metrics for shadow 46\n",
      "Computed metrics for shadow 47\n",
      "Computed metrics for shadow 48\n",
      "Computed metrics for shadow 49\n",
      "Computed metrics for shadow 50\n",
      "Computed metrics for shadow 51\n",
      "Computed metrics for shadow 52\n",
      "Computed metrics for shadow 53\n",
      "Computed metrics for shadow 54\n",
      "Computed metrics for shadow 55\n",
      "Computed metrics for shadow 56\n",
      "Computed metrics for shadow 57\n",
      "Computed metrics for shadow 58\n",
      "Computed metrics for shadow 59\n",
      "Computed metrics for shadow 60\n",
      "Computed metrics for shadow 61\n",
      "Computed metrics for shadow 62\n",
      "Computed metrics for shadow 63\n",
      "Computing statistics for losses...\n",
      "Computing statistics for logits...\n",
      "Computing statistics for scaled_logits...\n",
      "Computing statistics for target_logits...\n",
      "Performance Timings:\n",
      "Total computation time: 1336.10s\n",
      "Finished stats\n",
      "target_confs shape: (50000, 2), in_means shape: 50000, out_means shape: 50000\n",
      "[[28.56592169 24.59477441]\n",
      " [24.59477441 28.61039303]]\n",
      "Attack AUC: 0.5520610544000001\n",
      "✅ SUCCESS: Running LiRA attack on kd_0_mask completed in 1445.71s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', '-m', 'src.loss_traces.run_attack_pipeline', '--exp_id', 'kd_0_mask', '--target', 'target', '--arch', 'wrn28-2', '--dataset', 'CIFAR10', '--lira-only', '--layer', '0'], returncode=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([ \"python\", \"-m\", \"src.loss_traces.run_attack_pipeline\",\n",
    "    \"--exp_id\", \"kd_0_mask\",\n",
    "    \"--target\", \"target\",\n",
    "    \"--arch\", \"wrn28-2\",\n",
    "    \"--dataset\", \"CIFAR10\",\n",
    "    \"--lira-only\",\n",
    "    \"--layer\", \"0\",\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
